from fastapi import FastAPI, HTTPException, Form, Response
from pydantic import BaseModel
import uuid
import os
import requests
from openai import OpenAI
from dotenv import load_dotenv
from openai import AzureOpenAI
from RAG import search_query
from twilio.twiml.messaging_response import MessagingResponse

app = FastAPI(title="WeddingBot Sofia", description="IA de Q&A para bodas")

# Cargar variables desde el archivo .env
load_dotenv()

# Configuraci√≥n de Azure OpenAI Y AI Search
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_KEY = os.getenv("AZURE_SEARCH_KEY")
AZURE_INDEX_NAME = os.getenv("AZURE_INDEX_NAME")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Configuraci√≥n de Azure Search
search_service_endpoint = AZURE_SEARCH_ENDPOINT
index_name = AZURE_INDEX_NAME
search_api_key = AZURE_SEARCH_KEY 
api_search_version = "2024-11-01-preview"

class QueryRequest(BaseModel):
    session_id: str = None
    query: str

#creating an Azure OpenAI client
client = AzureOpenAI(
    api_key = AZURE_OPENAI_KEY,  
    api_version = "2024-02-15-preview",
    azure_endpoint = AZURE_OPENAI_ENDPOINT)

openai_client = OpenAI(api_key=OPENAI_API_KEY)

@app.get("/")
def home():
    return f"Bienvenido a {app.title}üöÄ"

@app.post("/chat")
def chat(request: QueryRequest):
    """
    Recibe una pregunta y devuelve una respuesta basada en RAG.
    Si no se proporciona session_id, genera uno autom√°ticamente.
    """
    # Generar session_id si no se proporciona
    session_id = request.session_id if request.session_id else str(uuid.uuid4())
    query = request.query

    try:

        # Configuraci√≥n de Azure Search
        search_service_endpoint = AZURE_SEARCH_ENDPOINT
        index_name = AZURE_INDEX_NAME
        search_api_key = AZURE_SEARCH_KEY 
        api_search_version = "2024-11-01-preview"

        context = search_query(client, query, search_api_key, search_service_endpoint, index_name, api_search_version)
        
        # Generar respuesta con GPT-4o
        system_prompt = f''' Eres **Sof√≠a**, la organizadora profesional de eventos encargada de asistir a los invitados de la 
                             boda de Laura Guadalupe Zaraz√∫a Arvizu y Jos√© Alberto Lozano S√°nchez. 
                             Atiendes por WhatsApp usando RAG con b√∫squeda sem√°ntica h√≠brida (Top‚Äë10).

                            üéØ **Fuente √∫nica**  
                            Solo extrae informaci√≥n de los **10 fragmentos** en `{context}`.  
                            Si no existe la respuesta, di literal:  
                            ‚ÄúMira, no tengo la informaci√≥n precisa por el momento, pero reviso con los novios en un momento‚Äù
                            solicitando al usuario formular la pregunta y sugiriendo **2 temas clave** adicionales sin realizar preguntas cerradas.

                            üß≠ **Tono y estilo**  
                            C√°lido, emp√°tico y profesional, como una event planner con experiencia.  
                            Frases cortas, claras y directas; nada de florituras.

                            üö´ **Cero alucinaciones**   No inventes ni supongas.  
                            No muestres tu proceso de b√∫squeda: entrega solo la respuesta final.

                            üìÇ **Uso de contexto**  
                            1. Antes de responder, selecciona solo los fragmentos **relevantes** de `{context}`.   
                            2. Coordina datos coherentes (hora, lugar, acci√≥n).

                            üó∫Ô∏è **Ubicaciones e im√°genes**  
                            Si preguntan por un lugar, incluye:  
                            ‚Ä¢ Direcci√≥n completa  
                            ‚Ä¢ Enlace de Google Maps  

                            üîÑ **Cierre proactivo**  
                            Al final, sugiere **2 temas clave** adicionales sobre la boda que el invitado 
                            podr√≠a preguntar siempre dentro del limite de la longitud de cada mensaje.   

                            üîÑ **Respuestas cerradas como Si o NO por parte del usuario**  
                            Si el usuario responde con un **SI** o **NO**, responde sugiriendo **4 temas clave**. 

                            ‚úÇÔ∏è **L√≠mite de longitud**  
                            Cada mensaje ‚â§ 1600 caracteres.  
                            Si excedes, sintetiza autom√°ticamente:  
                            ‚Ä¢ Prioriza lugar, hora, acciones, enlaces.  
                            ‚Ä¢ Usa vi√±etas si y solo si cabe m√°s informaci√≥n y con emojis acorde al contexto.
                            '''
        
        chat_history = []
        chat_history.append({"role": "system", "content": system_prompt})
        chat_history.append({"role": "user", "content": query})         

        # Generar respuesta con gpt-4.1
        gpt_response  = openai_client.chat.completions.create(
            model = "gpt-4.1",
            messages=chat_history,  # Enviar historial completo,
            max_tokens=1000,  
            temperature=0.8,  
            top_p=0.9,  
            frequency_penalty=0,  
            presence_penalty=0,
            stop=None,  
            stream=False  
        )

        response = gpt_response.choices[0].message.content
        session_id = str(uuid.uuid4())

        # Guardar en Cosmos DB
        chat_entry = {
            "session_id": session_id,
            "query": query,
            "response": response
            }

        return chat_entry
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
@app.post("/webhook")
def receive_msg_wp(From: str = Form(...), Body: str = Form(...)):
    """ Endpoint para recibir mensajes desde WhatsApp v√≠a Twilio """
    print(f"Mensaje recibido de {From}: {Body}")
    
    respuesta_bot = call_api_bot(Body)
    respuesta_twilio = MessagingResponse()
    msg = respuesta_twilio.message(respuesta_bot)

    # Nueva l√≥gica para agregar imagen del jard√≠n/recepci√≥n/terreno
    keywords1 = ["jard√≠n", "recepci√≥n", "terreno", "jardin", "recepcion", "fiesta", "peda", "evento"]
    if any(palabra in Body.lower() for palabra in keywords1):
        msg.media("https://sa19920811dev.blob.core.windows.net/images/foto_terreno.png")
    
    # Nueva l√≥gica para agregar imagen de la ceremonia religiosa
    keywords2 = ["misa", "ceremonia", "ceremonia reliogiosa", "parroquia", "parroqu√≠a", "iglesia"]
    if any(palabra in Body.lower() for palabra in keywords2):
        msg.media("https://sa19920811dev.blob.core.windows.net/images/foto_iglesia.jpg")

    return Response(content=str(respuesta_twilio), media_type="application/xml")

def call_api_bot(texto):
    """ Llama a la API del chatbot en Azure App Service y devuelve la respuesta """
    url = "https://weddingbotapp-escqeufmd8cbd3e8.eastus2-01.azurewebsites.net/chat"  
    payload = {"query": texto}
    headers = {"Content-Type": "application/json"}
    
    try:
        response = requests.post(url, json=payload, headers=headers)
        response_json = response.json()
        return response_json.get("response", "Disculpe, no entend√≠ su mensaje.")
    except Exception as e:
        return f"Error al comunicar con el bot: {str(e)}"
    
# uvicorn main:app --host 0.0.0.0 --port 8000 --reload